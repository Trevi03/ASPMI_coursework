{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hottbox.core import Tensor, TensorTKD\n",
    "from hottbox.algorithms.decomposition import HOSVD, HOOI\n",
    "from hottbox.utils.generation import residual_tensor\n",
    "from coursework.data import get_image, plot_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Table of Contents](./'0_Table_of_contents.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Multi-linear rank\n",
    "\n",
    "The **multi-linear rank** of a tensor $\\mathbf{\\underline{X}} \\in \\mathbb{R}^{I_1 \\times \\cdots \\times I_N}$ is the $N$-tuple $(R_1, \\dots, R_N)$ where each $R_n$ is the rank of the subspace spanned by mode-$n$ fibers, i.e. $R_n = \\text{rank} \\big( \\mathbf{X}_{(n)} \\big)$. Thus, for our order-$3$ tensor the multi-linear rank is $(R_1, R_2, R_3)$. Multi-linear rank provides flexibility in compression and approximation of the original tensor.\n",
    "\n",
    "> **NOTE:** For a tensor of order $N$ the values $R_1, R_2, \\dots , R_N$ are not necessarily the same, whereas, for matrices (tensors of order 2) the equality $R_1 = R_2$ always holds, where $R_1$ and $R_2$ are the matrix column rank and row rank respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing tensor decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tucker representation of a tensor with multi-linear rank=(4, 5, 6).\n",
      "Factor matrices represent properties: ['mode-0', 'mode-1', 'mode-2']\n",
      "With corresponding latent components described by (5, 6, 7) features respectively.\n",
      "\n",
      "\tFactor matrices\n",
      "Mode-0 factor matrix is of shape (5, 4)\n",
      "Mode-1 factor matrix is of shape (6, 5)\n",
      "Mode-2 factor matrix is of shape (7, 6)\n",
      "\n",
      "\tCore tensor\n",
      "This tensor is of order 3 and consists of 120 elements.\n",
      "Sizes and names of its modes are (4, 5, 6) and ['mode-0', 'mode-1', 'mode-2'] respectively.\n"
     ]
    }
   ],
   "source": [
    "# Create tensor\n",
    "I, J, K = 5, 6, 7\n",
    "array_3d = np.random.rand(I * J * K).reshape((I, J, K)).astype(float)\n",
    "tensor = Tensor(array_3d)\n",
    "\n",
    "# Initialise algorithm\n",
    "algorithm = HOSVD()\n",
    "\n",
    "# Perform decomposing for selected multi-linear rank\n",
    "ml_rank = (4, 5, 6)\n",
    "tensor_tkd = algorithm.decompose(tensor, ml_rank)\n",
    "\n",
    "# Result preview\n",
    "print(tensor_tkd)\n",
    "\n",
    "print('\\n\\tFactor matrices')\n",
    "for mode, fmat in enumerate(tensor_tkd.fmat):\n",
    "    print('Mode-{} factor matrix is of shape {}'.format(mode, fmat.shape))\n",
    "    \n",
    "print('\\n\\tCore tensor')\n",
    "print(tensor_tkd.core)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and reconstruction\n",
    "\n",
    "Tucker representation of an original tensor is almost always an approximation, regardless of which algorithm has been employed for performing decomposition. Thus, relative error of approximation is commonly used in order to evaluate performance of computational methods, i.e. the ratio between a Frobenious norms of residual and original tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error of approximation = 0.21320264561618074\n"
     ]
    }
   ],
   "source": [
    "# Compute residual tensor\n",
    "tensor_res = residual_tensor(tensor, tensor_tkd)\n",
    "\n",
    "# Compute error of approximation\n",
    "rel_error = tensor_res.frob_norm / tensor.frob_norm\n",
    "\n",
    "print(\"Relative error of approximation = {}\".format(rel_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Assigment 1**\n",
    "\n",
    "1. Create a tensor of order 4 with sizes of each mode being defined by prime numbers and  obtain a Tucker representation using HOOI algorithm with multi-linear (4, 10, 6, 2). Then calculation ratio between the number of elements in the original tensor and its Tucker form.\n",
    "\n",
    "1. For a tensor that consists of 1331 elements, which multi-linear rank guarantees a perfect reconstruction from its Tucker form and why. Is such choice reasonable for practical applications?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a tensor\n",
    "I, J, K, L = 2, 3, 5, 7\n",
    "array_4d = np.random.rand(I * J * K * L).reshape((I, J, K, L)).astype(float)\n",
    "tensor = Tensor(array_4d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tucker representation of a tensor with multi-linear rank=(2, 3, 5, 2).\n",
      "Factor matrices represent properties: ['mode-0', 'mode-1', 'mode-2', 'mode-3']\n",
      "With corresponding latent components described by (2, 3, 5, 7) features respectively.\n",
      "\n",
      "\tFactor matrices\n",
      "Mode-0 factor matrix is of shape (2, 2)\n",
      "Mode-1 factor matrix is of shape (3, 3)\n",
      "Mode-2 factor matrix is of shape (5, 5)\n",
      "Mode-3 factor matrix is of shape (7, 2)\n",
      "\n",
      "\tCore tensor\n",
      "This tensor is of order 4 and consists of 60 elements.\n",
      "Sizes and names of its modes are (2, 3, 5, 2) and ['mode-0', 'mode-1', 'mode-2', 'mode-3'] respectively.\n"
     ]
    }
   ],
   "source": [
    "# Perform decomposition\n",
    "\n",
    "# Initialise algorithm\n",
    "algorithm = HOSVD()\n",
    "\n",
    "# Perform decomposing for selected multi-linear rank\n",
    "ml_rank = (4, 10, 6, 2)\n",
    "tensor_tkd = algorithm.decompose(tensor, ml_rank)\n",
    "\n",
    "# Result preview\n",
    "print(tensor_tkd)\n",
    "\n",
    "print('\\n\\tFactor matrices')\n",
    "for mode, fmat in enumerate(tensor_tkd.fmat):\n",
    "    print('Mode-{} factor matrix is of shape {}'.format(mode, fmat.shape))\n",
    "    \n",
    "print('\\n\\tCore tensor')\n",
    "print(tensor_tkd.core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error of approximation = 0.3983801324193784\n",
      "Ratio between the number of elements in the original tensor and its Tucker form = 1.875\n"
     ]
    }
   ],
   "source": [
    "# Print ratio\n",
    "# Compute residual tensor\n",
    "tensor_res = residual_tensor(tensor, tensor_tkd)\n",
    "\n",
    "# Compute error of approximation\n",
    "rel_error = tensor_res.frob_norm / tensor.frob_norm\n",
    "\n",
    "print(\"Relative error of approximation = {}\".format(rel_error))\n",
    "\n",
    "# Compute no. elements in tensor\n",
    "tensorElements =  tensor.size\n",
    "# Compute no. elements in core tensor\n",
    "coreElements = tensor_tkd.core.size\n",
    "# Compute total no. elements across factor \n",
    "factElements = 0\n",
    "\n",
    "for i in range(np.shape(ml_rank)[0]):\n",
    "    \n",
    "    factElements += (np.shape(tensor_tkd.fmat[i])[0] * np.shape(tensor_tkd.fmat[i])[1])\n",
    "\n",
    "tuckerElements =  factElements + coreElements\n",
    "finalRatio = tensorElements/tuckerElements\n",
    "\n",
    "print(\"Ratio between the number of elements in the original tensor and its Tucker form = {}\".format(finalRatio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After decomposing 1331 elements into the prime factors (which creates the order of the core tensor of 3): 1331 = 11 x 11 x 11.\n",
    "For a perfect Tucker decomposition, the multi-linear ranks must exactly match the original tensor's dimensions. So the multi-linear rank is (11,11,11). \n",
    "This is because when ranks equal original dimensions, the core tensor becomes a full tensor where no compression or approximation occurs. The decomposition becomes just an identity transformation. However this defeats the primary purpose of tensor decomposition, where dimensionality reduction is desired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application: Image compression \n",
    "\n",
    "Color images can be naturally represented as a tensor of order three with the shape `(height x width x channels)` where channels are, for example, Red, Blue and Green (RGB)\n",
    "\n",
    "<img src=\"./imgs/image_to_base_colors.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "By keeping its original structure, allows to apply methods from multi-linear analysis. For instance, we can employ algorithms for Tucker decompositions in order to commress oringinal informaiton by varying values of desired multi-linear rank.\n",
    "\n",
    "```python\n",
    "# Get data in form of a Tensor\n",
    "car = get_image(item=\"car\", view=\"top\")\n",
    "tensor = Tensor(car)\n",
    "\n",
    "# Initialise algorithm and preform decomposition\n",
    "algorithm = HOSVD()\n",
    "tensor_tkd = algorithm.decompose(tensor, rank=(25, 25, 3))\n",
    "\n",
    "# Evaluate result\n",
    "tensor_res = residual_tensor(tensor, tensor_tkd)\n",
    "rel_error = tensor_res.frob_norm / tensor.frob_norm\n",
    "\n",
    "print(\"Relative error of approximation = {}\".format(rel_error))\n",
    "```\n",
    "\n",
    "When can also visually inspect image obtained by reconstructing the Tucker representation\n",
    "```python\n",
    "# Reconstruction\n",
    "tensor_rec = tensor_tkd.reconstruct()\n",
    "\n",
    "# Plot original and reconstructed images side by side\n",
    "plot_tensors(tensor, tensor_rec)\n",
    "```\n",
    "\n",
    "<img src=\"./imgs/car_orig_vs_reconstructed_25_25_3.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Assigment 2**\n",
    "For this assignment you are provided with function `get_image()` which requires two parameters: `item` and `view`. The valid values for former are **car** and **apple**, while the latter takes only **side** and **top**. \n",
    "\n",
    "1. Use multi-linear rank equal to `(50, 50, 2)` in order to obtain Tucker representations of images of the car and apple. Analyse results by visually inspecting their reconstructions.\n",
    "\n",
    "1. Use multi-linear rank equal to `(50, 50, 2)` in order to obtain Tucker representations of images of the apple taken from the top and from the side. Analyse results by visually inspecting their reconstructions.\n",
    "\n",
    "1. What would happen to the reconstruction if the value of multi-linear rank corresponding to the channel mode is decreased to 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors from images\n",
    "# car\n",
    "car = get_image(item=\"car\", view=\"top\")\n",
    "tensorCar = Tensor(car)\n",
    "# apple\n",
    "apple =  get_image(item=\"apple\",view=\"top\")\n",
    "tensorApple = Tensor(apple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform decomposition\n",
    "algorithm = HOSVD()\n",
    "tensor_tkdCar = algorithm.decompose(tensorCar, rank=(50, 50, 2))\n",
    "\n",
    "algorithm = HOSVD()\n",
    "tensor_tkdApple = algorithm.decompose(tensorApple, rank=(50, 50, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error of approximation for Car tensor = 0.08950050920521713\n",
      "Relative error of approximation for Apple tensor = 0.08277558463233754\n"
     ]
    }
   ],
   "source": [
    "# Evaluate results\n",
    "# Compute residual tensor\n",
    "tensor_res = residual_tensor(tensorCar, tensor_tkdCar)\n",
    "# Compute error of approximation\n",
    "rel_error = tensor_res.frob_norm / tensorCar.frob_norm\n",
    "print(\"Relative error of approximation for Car tensor = {}\".format(rel_error))\n",
    "\n",
    "# Reconstruction\n",
    "tensor_recCar = tensor_tkdCar.reconstruct()\n",
    "# Plot original and reconstructed images side by side\n",
    "plot_tensors(tensorCar, tensor_recCar)\n",
    "\n",
    "\n",
    "# Compute residual tensor\n",
    "tensor_res = residual_tensor(tensorApple, tensor_tkdApple)\n",
    "# Compute error of approximation\n",
    "rel_error = tensor_res.frob_norm / tensorApple.frob_norm\n",
    "print(\"Relative error of approximation for Apple tensor = {}\".format(rel_error))\n",
    "# Reconstruction\n",
    "tensor_recApple = tensor_tkdApple.reconstruct()\n",
    "# Plot original and reconstructed images side by side\n",
    "plot_tensors(tensorApple, tensor_recApple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Include your explanations here**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors from images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform decomposition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Include your explanations here**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Include your explanations here**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpm-coursework",
   "language": "python",
   "name": "dpm-coursework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
